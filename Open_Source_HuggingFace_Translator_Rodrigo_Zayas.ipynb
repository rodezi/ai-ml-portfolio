{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4vOhvtpHD/CSA92H+ZEvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodezi/ai-ml-portfolio/blob/main/Open_Source_HuggingFace_Translator_Rodrigo_Zayas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I'm using an Open Source HuggingFace LLM as a translator ---\n",
        "En este proyecto estoy usando un LLM Open Source de HuggingFace como traductor"
      ],
      "metadata": {
        "id": "Sk8gboDU02cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project im going to transate full english sentences to spanish"
      ],
      "metadata": {
        "id": "f2641Hjh2JO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este proyecto voy a traducir oraciones completas en ingles a español"
      ],
      "metadata": {
        "id": "CLURiynd2WCm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MiEGLWH56Lda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pl7BI6O9XQPs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MarianMTModel cargara un modelo de traduccion\n",
        "-\n",
        "MarianMTModel will charge a traslation model"
      ],
      "metadata": {
        "id": "SnalCMuZX3kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltYGi7QZXZuD",
        "outputId": "4e89b60b-7274-43be-a4fa-c3440caee4ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Hello, this is part of my first projects in my professional AI / Enginner portfolio. Welcome! \"]\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "cK6LxHZoX8GT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The translations its being generated and we decode the tokens ----\n",
        "Se genera la traducion y decodificamos los tokens."
      ],
      "metadata": {
        "id": "0HhLLybXY6Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traduccion_tokens = model.generate(**tokens)\n",
        "produccion_texto = tokenizer.batch_decode(traduccion_tokens, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "KbFZL-ZsYmYH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,t in zip (text,produccion_texto):\n",
        "  print(f\"Ingles: {i}\")\n",
        "  print(f\"Español: {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OuXakYzZAXe",
        "outputId": "bb65253b-a4d8-4d85-9e3d-b2090dfc5137"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingles: Hello, this is part of my first projects in my professional AI / Enginner portfolio. Welcome! \n",
            "Español: Hola, esto es parte de mis primeros proyectos en mi portafolio profesional de IA / Enginner. ¡Bienvenido!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"My name is Rodrigo, I'm looking for a AI / ML Engineer role. I'm in love with Python, AI agents and LLM's. They're very fun!\"]\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "traduccion_tokens = model.generate(**tokens)\n",
        "produccion_texto = tokenizer.batch_decode(traduccion_tokens, skip_special_tokens=True)\n",
        "\n",
        "for i,t in zip (text,produccion_texto):\n",
        "  print(f\"Ingles: {i}\")\n",
        "  print(f\"Español: {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lghAGJNp2hQv",
        "outputId": "7f8d83dc-57fb-41d9-9dab-74f2e21c56d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingles: My name is Rodrigo, I'm looking for a AI / ML Engineer role. I'm in love with Python, AI agents and LLM's. They're very fun!\n",
            "Español: Mi nombre es Rodrigo, estoy buscando un papel de Ingeniero de IA / ML. Estoy enamorado de Python, agentes de IA y LLM's. ¡Son muy divertidos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"This was an introduction project. Check my other projects! They're cool too!! \"]\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "traduccion_tokens = model.generate(**tokens)\n",
        "produccion_texto = tokenizer.batch_decode(traduccion_tokens, skip_special_tokens=True)\n",
        "\n",
        "for i,t in zip (text,produccion_texto):\n",
        "  print(f\"Ingles: {i}\")\n",
        "  print(f\"Español: {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxAS3tRha1Qn",
        "outputId": "a03d9410-59f5-423b-ef1d-c5e43868cd7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingles: This was an introduction project. Check my other projects! They're cool too!! \n",
            "Español: Este fue un proyecto de introducción. Compruebe mis otros proyectos! Son geniales también!!\n"
          ]
        }
      ]
    }
  ]
}